{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707f0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heartpy as hp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42447c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\Empatica'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:\\\\Users\\\\Owner\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\Empatica')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6011407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_lab_data(SubjID):\n",
    "    wd = os.getcwd() + '\\\\' + SubjID + '\\\\' + SubjID + '_baseline\\\\'\n",
    "    eda = hp.get_data(wd + 'EDA.csv')\n",
    "    bvp = hp.get_data(wd + 'BVP.csv')\n",
    "    acc = hp.get_data(wd + 'ACC.csv')\n",
    "    temp = hp.get_data(wd + 'TEMP.csv')\n",
    "    \n",
    "    init_time = datetime.fromtimestamp(eda[0]) #they all have the same initial time\n",
    "    \n",
    "    eda = eda[2:]\n",
    "    bvp = bvp[2:]\n",
    "    acc = acc[2:]\n",
    "    temp = temp[2:]\n",
    "    \n",
    "    eda_interval = timedelta(seconds=1/4)\n",
    "    bvp_interval = timedelta(seconds=1/64)\n",
    "    acc_interval = timedelta(seconds=1/32)\n",
    "    temp_interval = timedelta(seconds=1/4)\n",
    "    \n",
    "    eda_timestamps = [init_time + i * eda_interval for i in range(len(eda))]\n",
    "    bvp_timestamps = [init_time + i * bvp_interval for i in range(len(bvp))]\n",
    "    acc_timestamps = [init_time + i * acc_interval for i in range(len(acc))]\n",
    "    temp_timestamps = [init_time + i * temp_interval for i in range(len(temp))]\n",
    "    \n",
    "    # Create a new DataFrame with the timestamps and the original data columns\n",
    "    eda_df = pd.DataFrame(data = eda, columns=['EDA (4 Hz)'])\n",
    "    eda_df['timestamp'] = eda_timestamps\n",
    "\n",
    "    bvp_df = pd.DataFrame(data = bvp, columns=['BVP (64 Hz)'])\n",
    "    bvp_df['timestamp'] = bvp_timestamps\n",
    "\n",
    "    acc_df = pd.DataFrame(data = acc, columns=['ACC X (32 Hz)', 'ACC Y (32 Hz)', 'ACC Z (32 Hz)'])\n",
    "    acc_df['timestamp'] = acc_timestamps\n",
    "\n",
    "    temp_df = pd.DataFrame(data = temp, columns=['TEMP (4 Hz)'])\n",
    "    temp_df['timestamp'] = temp_timestamps\n",
    "    \n",
    "    #merge dataframes together, change column order and fill in NA values\n",
    "    merged_df = pd.merge(bvp_df, eda_df, on='timestamp', how='left').merge(acc_df, on='timestamp', how='left').merge(temp_df, on='timestamp', how='left')\n",
    "    \n",
    "    new_cols = ['timestamp','BVP (64 Hz)', 'EDA (4 Hz)','TEMP (4 Hz)','ACC X (32 Hz)','ACC Y (32 Hz)','ACC Z (32 Hz)',]\n",
    "\n",
    "    merged_df = merged_df[new_cols]\n",
    "    merged_df = merged_df.ffill(axis=0)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c663ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov4 = concatenate_lab_data('Cov4')\n",
    "cov7 = concatenate_lab_data('Cov7')\n",
    "cov8 = concatenate_lab_data('Cov8')\n",
    "cov13 = concatenate_lab_data('Cov13')\n",
    "cov14 = concatenate_lab_data('Cov14')\n",
    "cov20 = concatenate_lab_data('Cov20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e54129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to add the fatigue ratings\n",
    "ewd = 'C:\\\\Users\\\\Owner\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\E-Prime\\\\'\n",
    "\n",
    "def get_ratings(SubjID):\n",
    "    epr = pd.read_csv(ewd + SubjID + '\\\\' + SubjID + '_fatigue_ratings.txt', \n",
    "                      sep=':', encoding='UTF-16LE', on_bad_lines='skip')\n",
    "    epr = epr.filter(regex='FatigueRating', axis=0)\n",
    "    epr = epr.rename(columns={\"*** Header Start ***\": \"Rating\"})\n",
    "  \n",
    "    clean = []\n",
    "    for i in range(len(epr)):\n",
    "        try:\n",
    "            clean.append(int(pd.Series.tolist(epr.iloc[i])[0]))\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    d = {'Block': [0,1,2,3,4,5,6], 'Rating': clean}\n",
    "    clean_df = pd.DataFrame(d)\n",
    "    \n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b8417fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we also need to extract the tags for each block\n",
    "\n",
    "def add_blocks(SubjID, data):\n",
    "    wd = os.getcwd() + '\\\\' + SubjID + '\\\\' + SubjID + '_baseline\\\\'\n",
    "    tags = pd.read_csv(wd + 'tags.csv', header=None)\n",
    "    \n",
    "    if len(tags) != 9:\n",
    "        print(\"Incorrect number of tags. There are \" + str(len(tags)) + \" when there should be 9.\")\n",
    "        return None\n",
    "\n",
    "    tags = tags.applymap(datetime.fromtimestamp)\n",
    "     \n",
    "    # 0th and 1st tags marks baseline period. 2nd tag marks beginning of first block.\n",
    "    # We will remove data before 0th tag and between 1st and 2nd tags. Also remove extra data after 8th tag.\n",
    "    remove = data[ (data['timestamp'] < tags.iloc[0,0]) | \n",
    "                  ((data['timestamp'] > tags.iloc[1,0]) & (data['timestamp'] < tags.iloc[2,0])) |\n",
    "                  (data['timestamp'] > tags.iloc[8,0])].index\n",
    "\n",
    "    df = data.drop(remove)\n",
    "    \n",
    "    # Add block numbers to dataframe\n",
    "    conditions = [\n",
    "        (df['timestamp'] < tags.iloc[1,0]),\n",
    "        (df['timestamp'] >= tags.iloc[2,0]) & (df['timestamp'] < tags.iloc[3,0]),\n",
    "        (df['timestamp'] >= tags.iloc[3,0]) & (df['timestamp'] < tags.iloc[4,0]),\n",
    "        (df['timestamp'] >= tags.iloc[4,0]) & (df['timestamp'] < tags.iloc[5,0]),\n",
    "        (df['timestamp'] >= tags.iloc[5,0]) & (df['timestamp'] < tags.iloc[6,0]),\n",
    "        (df['timestamp'] >= tags.iloc[6,0]) & (df['timestamp'] < tags.iloc[7,0]),\n",
    "        (df['timestamp'] >= tags.iloc[7,0]) & (df['timestamp'] < tags.iloc[8,0])\n",
    "    ]\n",
    "    ratings = get_ratings(SubjID)\n",
    "    \n",
    "    df['Block'] = np.select(conditions, ratings['Block'])\n",
    "    df['Fatigue_Rating'] = np.select(conditions, ratings['Rating'])\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0caf992d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cov4_rat = add_blocks('Cov4', cov4)\n",
    "cov7_rat = add_blocks('Cov7', cov7)\n",
    "cov8_rat = add_blocks('Cov8', cov8)\n",
    "cov13_rat = add_blocks('Cov13', cov13)\n",
    "cov14_rat = add_blocks('Cov14', cov14)\n",
    "cov20_rat = add_blocks('Cov20', cov20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ab48af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwd = 'C:\\\\Users\\\\Owner\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\Concatenated_Data\\\\'\n",
    "\n",
    "cov4_rat.to_csv(nwd + 'Cov4_lab.csv', index=False)\n",
    "cov7_rat.to_csv(nwd + 'Cov7_lab.csv', index=False)\n",
    "cov8_rat.to_csv(nwd + 'Cov8_lab.csv', index=False)\n",
    "cov13_rat.to_csv(nwd + 'Cov13_lab.csv', index=False)\n",
    "cov14_rat.to_csv(nwd + 'Cov14_lab.csv', index=False)\n",
    "cov20_rat.to_csv(nwd + 'Cov20_lab.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
