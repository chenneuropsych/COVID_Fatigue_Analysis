{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9ea706",
   "metadata": {},
   "source": [
    "# Concatenating Data (and upsampling ACC data)\n",
    "\n",
    "This code file creates a singular dataframe for BVP, EDA, TEMP, ACC X Y & Z data for each participant. The BVP, EDA and TEMP data are not upsampled, and the missing values are repeated. The ACC data is upsampled to 64 Hz to match the BVP sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707f0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42447c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\katgm\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\Empatica'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:\\\\Users\\\\katgm\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\Empatica')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6011407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_lab_data(SubjID):\n",
    "    wd = os.getcwd() + '\\\\' + SubjID + '\\\\' + SubjID + '_baseline\\\\'\n",
    "    eda = pd.read_csv(wd + 'EDA.csv', header=None).to_numpy().flatten()\n",
    "    bvp = pd.read_csv(wd + 'BVP.csv', header=None).to_numpy().flatten()\n",
    "    acc = pd.read_csv(wd + 'ACC.csv', header=None).to_numpy()\n",
    "    temp = pd.read_csv(wd + 'TEMP.csv', header=None).to_numpy().flatten()\n",
    "    \n",
    "    init_time = datetime.fromtimestamp(eda[0]) #they all have the same initial time\n",
    "    \n",
    "    eda = eda[2:]\n",
    "    bvp = bvp[2:]\n",
    "    acc = acc[2:]\n",
    "    temp = temp[2:]\n",
    "    \n",
    "    eda_interval = timedelta(seconds=1/4)\n",
    "    bvp_interval = timedelta(seconds=1/64)\n",
    "    acc_interval = timedelta(seconds=1/32)\n",
    "    temp_interval = timedelta(seconds=1/4)\n",
    "    \n",
    "    eda_timestamps = [init_time + i * eda_interval for i in range(len(eda))]\n",
    "    bvp_timestamps = [init_time + i * bvp_interval for i in range(len(bvp))]\n",
    "    acc_timestamps = [init_time + i * acc_interval for i in range(len(acc))]\n",
    "    temp_timestamps = [init_time + i * temp_interval for i in range(len(temp))]\n",
    "    \n",
    "    # Create a new DataFrame with the timestamps and the original data columns\n",
    "    eda_df = pd.DataFrame(data = eda, columns=['EDA (4 Hz)'])\n",
    "    eda_df['timestamp'] = eda_timestamps\n",
    "\n",
    "    bvp_df = pd.DataFrame(data = bvp, columns=['BVP (64 Hz)'])\n",
    "    bvp_df['timestamp'] = bvp_timestamps\n",
    "\n",
    "    acc_df = pd.DataFrame(data = acc, columns=['ACC X (32 Hz)', 'ACC Y (32 Hz)', 'ACC Z (32 Hz)'])\n",
    "    acc_df['timestamp'] = acc_timestamps\n",
    "\n",
    "    temp_df = pd.DataFrame(data = temp, columns=['TEMP (4 Hz)'])\n",
    "    temp_df['timestamp'] = temp_timestamps\n",
    " \n",
    "    #merge dataframes together, change column order, LEAVING NA values, because we should filter the signal first!\n",
    "    merged_df = pd.merge(bvp_df, eda_df, on='timestamp', how='left').merge(acc_df, on='timestamp', how='left').merge(temp_df, on='timestamp', how='left')\n",
    "    \n",
    "    new_cols = ['timestamp','BVP (64 Hz)', 'EDA (4 Hz)','TEMP (4 Hz)','ACC X (32 Hz)','ACC Y (32 Hz)','ACC Z (32 Hz)']\n",
    "    \n",
    "    merged_df = merged_df[new_cols]\n",
    "    # merged_df['EDA (4 Hz)'].ffill(axis=0, inplace=True)\n",
    "    # merged_df['TEMP (4 Hz)'].ffill(axis=0, inplace=True)\n",
    "    \n",
    "    # instead of repeating values in ACC columns, interpolate missing values\n",
    "    # Uses linear interpolation method\n",
    "    # merged_df.interpolate(method = 'linear', inplace=True)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c663ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov4 = concatenate_lab_data('Cov4')\n",
    "cov7 = concatenate_lab_data('Cov7')\n",
    "cov8 = concatenate_lab_data('Cov8')\n",
    "cov13 = concatenate_lab_data('Cov13')\n",
    "cov14 = concatenate_lab_data('Cov14')\n",
    "cov20 = concatenate_lab_data('Cov20')\n",
    "cov19 = concatenate_lab_data('Cov19')\n",
    "cov22 = concatenate_lab_data('Cov22')\n",
    "cov23 = concatenate_lab_data('Cov23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0437d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "covtest = concatenate_lab_data('CovTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e54129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to add the fatigue ratings\n",
    "ewd = 'C:\\\\Users\\\\Owner\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\E-Prime\\\\'\n",
    "\n",
    "def get_ratings(SubjID):\n",
    "    epr = pd.read_csv(ewd + SubjID + '\\\\' + SubjID + '_fatigue_ratings.txt', \n",
    "                      sep=':', encoding='UTF-16LE', on_bad_lines='skip')\n",
    "    epr = epr.filter(regex='FatigueRating', axis=0)\n",
    "    epr = epr.rename(columns={\"*** Header Start ***\": \"Rating\"})\n",
    "  \n",
    "    clean = []\n",
    "    for i in range(len(epr)):\n",
    "        try:\n",
    "            clean.append(int(pd.Series.tolist(epr.iloc[i])[0]))\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    d = {'Block': [0,1,2,3,4,5,6], 'Rating': clean}\n",
    "    clean_df = pd.DataFrame(d)\n",
    "    \n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8417fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we also need to extract the tags for each block\n",
    "\n",
    "def add_blocks(SubjID, data):\n",
    "    wd = os.getcwd() + '\\\\' + SubjID + '\\\\' + SubjID + '_baseline\\\\'\n",
    "    tags = pd.read_csv(wd + 'tags.csv', header=None)\n",
    "    \n",
    "    if len(tags) != 9:\n",
    "        print(\"Incorrect number of tags. There are \" + str(len(tags)) + \" when there should be 9.\")\n",
    "        return None\n",
    "\n",
    "    tags = tags.applymap(datetime.fromtimestamp)\n",
    "     \n",
    "    # 0th and 1st tags marks baseline period. 2nd tag marks beginning of first block.\n",
    "    # We will remove data before 0th tag and between 1st and 2nd tags. Also remove extra data after 8th tag.\n",
    "    # REMOVING THE DATA IS CAUSING ME PHYSICAL PAIN, WILL DO AFTER PRE-PROCESSING\n",
    "    # NOT REMOVING THE ENDING DATA IS CAUSING ME MENTAL FATIGUE, so we're doing that\n",
    "    #remove = data[ (data['timestamp'] < tags.iloc[0,0]) | \n",
    "                 # ((data['timestamp'] > tags.iloc[1,0]) & (data['timestamp'] < tags.iloc[2,0])) |\n",
    "                 # (data['timestamp'] > tags.iloc[8,0])].index\n",
    "            \n",
    "    remove = data[(data['timestamp'] > tags.iloc[8,0])].index\n",
    "    df = data.drop(remove)\n",
    "    \n",
    "    \n",
    "    # Add block numbers to dataframe\n",
    "    conditions = [\n",
    "        (df['timestamp'] >= tags.iloc[0,0]) & (df['timestamp'] < tags.iloc[1,0]),\n",
    "        (df['timestamp'] >= tags.iloc[2,0]) & (df['timestamp'] < tags.iloc[3,0]),\n",
    "        (df['timestamp'] >= tags.iloc[3,0]) & (df['timestamp'] < tags.iloc[4,0]),\n",
    "        (df['timestamp'] >= tags.iloc[4,0]) & (df['timestamp'] < tags.iloc[5,0]),\n",
    "        (df['timestamp'] >= tags.iloc[5,0]) & (df['timestamp'] < tags.iloc[6,0]),\n",
    "        (df['timestamp'] >= tags.iloc[6,0]) & (df['timestamp'] < tags.iloc[7,0]),\n",
    "        (df['timestamp'] >= tags.iloc[7,0]) & (df['timestamp'] < tags.iloc[8,0])\n",
    "    ]\n",
    "    ratings = get_ratings(SubjID)\n",
    "\n",
    "    df['Block'] = np.select(conditions, ratings['Block'], default=pd.NA)\n",
    "    df['Fatigue_Rating'] = np.select(conditions, ratings['Rating'], default=pd.NA)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0caf992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov4_rat = add_blocks('Cov4', cov4)\n",
    "cov7_rat = add_blocks('Cov7', cov7)\n",
    "cov8_rat = add_blocks('Cov8', cov8)\n",
    "cov13_rat = add_blocks('Cov13', cov13)\n",
    "cov14_rat = add_blocks('Cov14', cov14)\n",
    "cov20_rat = add_blocks('Cov20', cov20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab48af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwd = 'C:\\\\Users\\\\Owner\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\Concatenated_Data\\\\'\n",
    "\n",
    "cov4_rat.to_csv(nwd + 'Cov4_lab.csv', index=False)\n",
    "cov7_rat.to_csv(nwd + 'Cov7_lab.csv', index=False)\n",
    "cov8_rat.to_csv(nwd + 'Cov8_lab.csv', index=False)\n",
    "cov13_rat.to_csv(nwd + 'Cov13_lab.csv', index=False)\n",
    "cov14_rat.to_csv(nwd + 'Cov14_lab.csv', index=False)\n",
    "cov20_rat.to_csv(nwd + 'Cov20_lab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0b77dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwd = 'C:\\\\Users\\\\katgm\\\\Rutgers University\\\\Michelle Chen - Rutgers_Neuropsych_Lab\\\\COVID_Fatigue\\\\RC_award\\\\Data\\\\Concatenated_Data\\\\'\n",
    "covtest.to_csv(nwd + 'CovTest2_lab.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
